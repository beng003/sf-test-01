{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b6b37c9",
   "metadata": {},
   "source": [
    "# Using Custom DataBuilder in SecretFlow (TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e57a23",
   "metadata": {},
   "source": [
    "The following codes are demos only. It's **NOT for production** due to system security concerns, please **DO NOT** use it directly in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8528a86e",
   "metadata": {},
   "source": [
    "In this tutorial, we will show you how to load data and train model using the custom DataBuilder schema in the multi-party secure environment of SecretFlow.\n",
    "This tutorial will use the image classification task of the Flower dataset to introduce, how to use the custom DataBuilder to complete federated learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e55b2",
   "metadata": {},
   "source": [
    "## Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c08ecd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "812c6aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of SecretFlow: 1.8.0b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beng003/anaconda/envs/sf/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _posixsubprocess.fork_exec(\n",
      "2024-08-13 18:17:28,686\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import secretflow as sf\n",
    "\n",
    "# Check the version of your SecretFlow\n",
    "print('The version of SecretFlow: {}'.format(sf.__version__))\n",
    "\n",
    "# In case you have a running secretflow runtime already.\n",
    "sf.shutdown()\n",
    "sf.init(['alice', 'bob'], address=\"local\", log_to_driver=False)\n",
    "alice, bob= sf.PYU('alice'), sf.PYU('bob')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c38ba4",
   "metadata": {},
   "source": [
    "## Interface Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509e5461",
   "metadata": {},
   "source": [
    "We support custom DataBuilder reads in SecretFlow's `FLModel` to make it easier for users to handle data inputs more flexibly according to their needs.\n",
    "Let's use an example to demonstrate how to use the custom DataBuilder for federated model training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff157baf",
   "metadata": {},
   "source": [
    "Steps to use DataBuilder:\n",
    "\n",
    "1. Use the single-machine version engine (TensorFlow, PyTorch) to develop and get the Builder function of the Dataset.\n",
    "2. Wrap the Builder functions of each party to get `create_dataset_builder` function. *Note: The dataset_builder needs to pass in the stage parameter.*\n",
    "3. Build the data_builder_dict [PYU, dataset_builder].\n",
    "4. Pass the obtained data_builder_dict to the `dataset_builder` of the `fit` function. At the same time, the x parameter position is passed into the required input in dataset_builder (eg: the input passed in this example is the actual image path used)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad75fd6",
   "metadata": {},
   "source": [
    "Using DataBuilder in FLModel requires a pre-defined `data_builder_dict`. Need to be able to return `tf.dataset` and `steps_per_epoch`. And the steps_per_epoch returned by all parties must be consistent.\n",
    "```python\n",
    "data_builder_dict = \n",
    "        {\n",
    "            alice: create_alice_dataset_builder(\n",
    "                batch_size=32,\n",
    "            ), # create_alice_dataset_builder must return (Dataset, steps_per_epoch)\n",
    "            bob: create_bob_dataset_builder(\n",
    "                batch_size=32,\n",
    "            ), # create_bob_dataset_builder must return (Dataset, steps_per_epochstep_per_epochs)\n",
    "        }\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b0faf",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ffc09e",
   "metadata": {},
   "source": [
    "Flower Dataset Introduction: The Flower dataset consists of 4323 color images of 5 different types of flowers (daisy, dandelion, rose, sunflower, and tulip). Each flower has images from multiple angles and different lighting conditions, and the resolution of each image is 320x240.\n",
    "This dataset is commonly used for training and testing of image classification and machine learning algorithms. The number of each category in the dataset is as follows: daisy (633), dandelion (898), rose (641), sunflower (699), and tulip (852).\n",
    "\n",
    "Download link: [http://download.tensorflow.org/example_images/flower_photos.tgz](http://download.tensorflow.org/example_images/flower_photos.tgz)\n",
    "\n",
    "<img alt=\"flower_dataset_demo.png\" src=\"resources/flower_dataset_demo.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f5d14",
   "metadata": {},
   "source": [
    "### Download Data and Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff9720cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import tensorflow as tf\n",
    "\n",
    "# _temp_dir = \"/home/beng003/python_project/sf-test/data\"\n",
    "# path_to_flower_dataset = tf.keras.utils.get_file(\n",
    "#     \"flower_photos\",\n",
    "#     \"https://secretflow-data.oss-accelerate.aliyuncs.com/datasets/tf_flowers/flower_photos.tgz\",\n",
    "#     untar=True,\n",
    "#     cache_dir=_temp_dir,\n",
    "# )\n",
    "\n",
    "path_to_flower_dataset =  \"/home/beng003/python_project/sf-test/data/datasets/flower_photos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c94caaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/beng003/python_project/sf-test/data/datasets/flower_photos'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_flower_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f1057",
   "metadata": {},
   "source": [
    "Next let's start building a custom DataBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d98ab3",
   "metadata": {},
   "source": [
    "## 1. Develop DataBuilder with single-machine version engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c81834d",
   "metadata": {},
   "source": [
    "When we develop DataBuilder, we are free to follow the logic of single-machine development.\n",
    "The purpose is to build a `tf.dataset` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfe48fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 files belonging to 5 classes.\n",
      "Using 20 files for training.\n",
      "Using 5 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "batch_size = 5\n",
    "# In this example, we use the TensorFlow interface for development.\n",
    "data_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_to_flower_dataset,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e086dc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_BatchDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>,\n",
       " <_BatchDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8106f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data_set[0]\n",
    "test_set = data_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096c39e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37dd53fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.batch_op._BatchDataset'> <class 'tensorflow.python.data.ops.batch_op._BatchDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_set), type(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4199b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (5, 180, 180, 3)\n",
      "y.shape = (5,)\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_set))\n",
    "print(f\"x.shape = {x.shape}\")\n",
    "print(f\"y.shape = {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f06f6a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 180, 180, 3), dtype=float32, numpy=\n",
       "array([[[[1.91666672e+02, 1.36166672e+02, 6.10000000e+01],\n",
       "         [1.92491669e+02, 1.36991669e+02, 6.18250008e+01],\n",
       "         [1.93375000e+02, 1.37875000e+02, 6.27083321e+01],\n",
       "         ...,\n",
       "         [2.24500000e+02, 1.61500000e+02, 6.62638931e+01],\n",
       "         [2.24500000e+02, 1.61500000e+02, 6.67916718e+01],\n",
       "         [2.24500000e+02, 1.61500000e+02, 6.81666641e+01]],\n",
       "\n",
       "        [[1.90000000e+02, 1.37000000e+02, 6.10000000e+01],\n",
       "         [1.90412506e+02, 1.37412506e+02, 6.14124985e+01],\n",
       "         [1.91208328e+02, 1.38208328e+02, 6.22083321e+01],\n",
       "         ...,\n",
       "         [2.29000000e+02, 1.65500000e+02, 6.84375076e+01],\n",
       "         [2.29000000e+02, 1.65500000e+02, 6.95000000e+01],\n",
       "         [2.29000000e+02, 1.65500000e+02, 6.95000000e+01]],\n",
       "\n",
       "        [[1.89166672e+02, 1.36166672e+02, 6.01666679e+01],\n",
       "         [1.89854156e+02, 1.36854156e+02, 6.08541679e+01],\n",
       "         [1.90708328e+02, 1.37708328e+02, 6.17083321e+01],\n",
       "         ...,\n",
       "         [2.31833328e+02, 1.67833328e+02, 6.87014008e+01],\n",
       "         [2.31833328e+02, 1.67833328e+02, 7.00000000e+01],\n",
       "         [2.31833328e+02, 1.67833328e+02, 7.00000000e+01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.13500076e+02, 1.49333374e+02, 3.61667023e+01],\n",
       "         [2.15837555e+02, 1.55658371e+02, 3.20417519e+01],\n",
       "         [2.07951462e+02, 1.47673660e+02, 4.28542328e+01],\n",
       "         ...,\n",
       "         [9.92226105e+01, 7.54239426e+01, 1.70629177e+01],\n",
       "         [1.29895813e+02, 1.02045853e+02, 4.90793419e+01],\n",
       "         [5.63332825e+01, 4.33333130e+01, 4.66665649e+00]],\n",
       "\n",
       "        [[2.27000000e+02, 1.55500000e+02, 4.30000000e+01],\n",
       "         [2.24937500e+02, 1.62100006e+02, 5.12500000e+01],\n",
       "         [2.21666656e+02, 1.57833344e+02, 5.72500000e+01],\n",
       "         ...,\n",
       "         [9.96671753e+01, 7.46254120e+01, 2.85838318e+01],\n",
       "         [1.49499634e+02, 1.16424728e+02, 8.11122055e+01],\n",
       "         [5.05000000e+01, 4.30000000e+01, 1.50000000e+00]],\n",
       "\n",
       "        [[2.33000061e+02, 1.59166718e+02, 5.15000916e+01],\n",
       "         [2.27225006e+02, 1.62604156e+02, 6.25000725e+01],\n",
       "         [2.18090195e+02, 1.51291565e+02, 5.63332748e+01],\n",
       "         ...,\n",
       "         [8.99029617e+01, 6.49375610e+01, 8.75001049e+00],\n",
       "         [1.10416328e+02, 7.30122375e+01, 2.51870193e+01],\n",
       "         [7.46669312e+01, 6.60002441e+01, 2.50003052e+00]]],\n",
       "\n",
       "\n",
       "       [[[3.41666679e+01, 3.85000000e+01, 1.50000000e+01],\n",
       "         [5.15763855e+01, 5.50013885e+01, 2.78680553e+01],\n",
       "         [7.74791718e+01, 7.92592621e+01, 4.61111107e+01],\n",
       "         ...,\n",
       "         [1.98796692e+01, 2.64977036e+01, 8.62502575e+00],\n",
       "         [2.36194248e+01, 2.89903355e+01, 1.12430620e+01],\n",
       "         [2.15000000e+01, 3.55000000e+01, 1.20000000e+01]],\n",
       "\n",
       "        [[3.40000000e+01, 4.25000000e+01, 1.45000000e+01],\n",
       "         [5.12583313e+01, 5.88499985e+01, 2.72166653e+01],\n",
       "         [7.37569504e+01, 7.91388855e+01, 4.33263931e+01],\n",
       "         ...,\n",
       "         [2.04583588e+01, 2.84583588e+01, 8.95835876e+00],\n",
       "         [2.32291870e+01, 3.18250732e+01, 1.15000000e+01],\n",
       "         [2.55000000e+01, 4.00000000e+01, 1.15000000e+01]],\n",
       "\n",
       "        [[2.55000000e+01, 3.90000000e+01, 6.49999952e+00],\n",
       "         [4.10930557e+01, 5.21708336e+01, 1.83083305e+01],\n",
       "         [6.56828766e+01, 7.59513855e+01, 3.71504631e+01],\n",
       "         ...,\n",
       "         [2.03310375e+01, 3.18310375e+01, 9.74306011e+00],\n",
       "         [2.25333652e+01, 3.43542290e+01, 1.00138750e+01],\n",
       "         [2.61666660e+01, 4.11666679e+01, 8.50000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[5.26666870e+01, 6.60000610e+01, 3.71665192e+01],\n",
       "         [5.96304855e+01, 8.05332489e+01, 1.56694460e+01],\n",
       "         [4.46596527e+01, 6.66087036e+01, 3.75699711e+00],\n",
       "         ...,\n",
       "         [2.08666656e+02, 2.20666656e+02, 2.42717590e+02],\n",
       "         [2.08620819e+02, 2.20743057e+02, 2.42618027e+02],\n",
       "         [2.08166672e+02, 2.21500015e+02, 2.38833359e+02]],\n",
       "\n",
       "        [[5.65000000e+01, 7.85000000e+01, 1.70000000e+01],\n",
       "         [4.96875000e+01, 7.16875000e+01, 1.47291670e+01],\n",
       "         [4.22222214e+01, 6.25277786e+01, 1.66180553e+01],\n",
       "         ...,\n",
       "         [2.06500000e+02, 2.18500000e+02, 2.41652786e+02],\n",
       "         [2.06454163e+02, 2.18729187e+02, 2.42362488e+02],\n",
       "         [2.06000000e+02, 2.21000000e+02, 2.41000000e+02]],\n",
       "\n",
       "        [[5.03332520e+01, 7.68332825e+01, 3.49978638e+00],\n",
       "         [6.07792778e+01, 8.80362625e+01, 1.51569614e+01],\n",
       "         [4.20647049e+01, 6.64327698e+01, 1.26619396e+01],\n",
       "         ...,\n",
       "         [2.06000000e+02, 2.18000000e+02, 2.42000000e+02],\n",
       "         [2.05801376e+02, 2.18076401e+02, 2.41954163e+02],\n",
       "         [2.03833344e+02, 2.18833344e+02, 2.41500031e+02]]],\n",
       "\n",
       "\n",
       "       [[[2.33266663e+02, 2.05674072e+02, 2.10622223e+02],\n",
       "         [2.28540741e+02, 1.99185196e+02, 2.11451843e+02],\n",
       "         [2.22908646e+02, 1.59765442e+02, 1.90920990e+02],\n",
       "         ...,\n",
       "         [2.02812347e+02, 1.73298737e+02, 1.69555542e+02],\n",
       "         [2.03577881e+02, 1.74140732e+02, 1.74192612e+02],\n",
       "         [1.98358047e+02, 1.77580215e+02, 1.74469131e+02]],\n",
       "\n",
       "        [[2.28874084e+02, 1.96777771e+02, 2.01614807e+02],\n",
       "         [2.25288895e+02, 1.82488892e+02, 2.02155563e+02],\n",
       "         [2.18925934e+02, 1.47637039e+02, 1.85051849e+02],\n",
       "         ...,\n",
       "         [2.00674057e+02, 1.71992569e+02, 1.68111084e+02],\n",
       "         [2.02644440e+02, 1.75666626e+02, 1.74666626e+02],\n",
       "         [2.01562958e+02, 1.80785126e+02, 1.77674042e+02]],\n",
       "\n",
       "        [[2.28320999e+02, 1.82901245e+02, 1.93876541e+02],\n",
       "         [2.23555557e+02, 1.61814819e+02, 1.93666656e+02],\n",
       "         [2.17839508e+02, 1.40037033e+02, 1.78925919e+02],\n",
       "         ...,\n",
       "         [2.01123459e+02, 1.71728348e+02, 1.68172806e+02],\n",
       "         [2.04185181e+02, 1.76703659e+02, 1.75777740e+02],\n",
       "         [2.04345642e+02, 1.83567810e+02, 1.80456726e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.05283958e+02, 1.38098770e+02, 1.13197533e+02],\n",
       "         [9.17407532e+01, 1.13407417e+02, 1.00592606e+02],\n",
       "         [5.84197693e+01, 9.08271637e+01, 5.70864258e+01],\n",
       "         ...,\n",
       "         [2.26295834e+01, 6.87039108e+01, 3.81729774e+01],\n",
       "         [8.32963791e+01, 1.14370071e+02, 9.03701706e+01],\n",
       "         [3.72467041e+01, 7.31851120e+01, 1.19012623e+01]],\n",
       "\n",
       "        [[1.08859261e+02, 1.40081482e+02, 1.21748146e+02],\n",
       "         [8.54666595e+01, 1.20799988e+02, 1.03799988e+02],\n",
       "         [6.28666420e+01, 8.33110886e+01, 5.68666458e+01],\n",
       "         ...,\n",
       "         [2.85187588e+01, 6.05036125e+01, 2.94816704e+01],\n",
       "         [7.16003952e+01, 1.18266945e+02, 8.25562668e+01],\n",
       "         [4.01403389e+01, 7.06589127e+01, 1.63701572e+01]],\n",
       "\n",
       "        [[1.08661743e+02, 1.39883957e+02, 1.21550629e+02],\n",
       "         [7.94593124e+01, 1.14792648e+02, 9.77926483e+01],\n",
       "         [5.23383522e+01, 7.27827988e+01, 4.63383522e+01],\n",
       "         ...,\n",
       "         [3.57135811e+01, 6.39283562e+01, 3.18816967e+01],\n",
       "         [6.36231766e+01, 1.11008430e+02, 6.88014679e+01],\n",
       "         [4.52762413e+01, 7.11380005e+01, 1.44443359e+01]]],\n",
       "\n",
       "\n",
       "       [[[9.00000000e+01, 1.05000000e+02, 1.02000000e+02],\n",
       "         [9.09666672e+01, 1.05966667e+02, 1.02966667e+02],\n",
       "         [9.19444427e+01, 1.06944443e+02, 1.03944443e+02],\n",
       "         ...,\n",
       "         [1.63000000e+02, 1.65055557e+02, 1.40888885e+02],\n",
       "         [1.63000000e+02, 1.66000000e+02, 1.39000000e+02],\n",
       "         [1.63000000e+02, 1.66000000e+02, 1.39000000e+02]],\n",
       "\n",
       "        [[8.95000000e+01, 1.04500000e+02, 1.01500000e+02],\n",
       "         [9.04666672e+01, 1.05466667e+02, 1.02466667e+02],\n",
       "         [9.14444427e+01, 1.06444443e+02, 1.03444443e+02],\n",
       "         ...,\n",
       "         [1.63000000e+02, 1.65055557e+02, 1.40888885e+02],\n",
       "         [1.63000000e+02, 1.66000000e+02, 1.39000000e+02],\n",
       "         [1.63000000e+02, 1.66000000e+02, 1.39000000e+02]],\n",
       "\n",
       "        [[8.81666641e+01, 1.02333336e+02, 1.01833336e+02],\n",
       "         [8.91333313e+01, 1.03300003e+02, 1.02800003e+02],\n",
       "         [9.01111069e+01, 1.04277779e+02, 1.03777779e+02],\n",
       "         ...,\n",
       "         [1.63046295e+02, 1.65101852e+02, 1.40935181e+02],\n",
       "         [1.63833328e+02, 1.66833328e+02, 1.39833328e+02],\n",
       "         [1.63833328e+02, 1.66833328e+02, 1.39833328e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.71666718e+01, 1.81666718e+01, 4.16667175e+00],\n",
       "         [1.99055557e+01, 2.09055557e+01, 6.90555573e+00],\n",
       "         [2.18888893e+01, 2.28888893e+01, 8.88888931e+00],\n",
       "         ...,\n",
       "         [9.78054657e+01, 9.29813919e+01, 5.35184479e+01],\n",
       "         [9.48000488e+01, 9.01333923e+01, 5.13667755e+01],\n",
       "         [1.03499954e+02, 9.88332977e+01, 6.20000000e+01]],\n",
       "\n",
       "        [[1.90000000e+01, 2.00000000e+01, 6.00000000e+00],\n",
       "         [2.14166679e+01, 2.24166679e+01, 8.41666603e+00],\n",
       "         [2.29166679e+01, 2.39166679e+01, 9.91666698e+00],\n",
       "         ...,\n",
       "         [7.56110992e+01, 7.31666565e+01, 3.93611069e+01],\n",
       "         [6.87332764e+01, 6.72666168e+01, 3.68666382e+01],\n",
       "         [6.10000000e+01, 6.05000000e+01, 3.30000000e+01]],\n",
       "\n",
       "        [[2.33333740e+01, 2.43333740e+01, 1.03333740e+01],\n",
       "         [2.54278088e+01, 2.64278088e+01, 1.24278088e+01],\n",
       "         [2.64444752e+01, 2.74444752e+01, 1.34444752e+01],\n",
       "         ...,\n",
       "         [4.41107750e+01, 4.49256134e+01, 1.46478672e+01],\n",
       "         [1.84164982e+01, 2.17332020e+01, 3.61662865e+00],\n",
       "         [4.01668396e+01, 4.30001831e+01, 2.15002136e+01]]],\n",
       "\n",
       "\n",
       "       [[[2.26638901e+02, 2.04925919e+02, 3.24074090e-01],\n",
       "         [2.24194443e+02, 2.00500000e+02, 1.83333325e+00],\n",
       "         [2.30268524e+02, 2.08370377e+02, 7.96296418e-01],\n",
       "         ...,\n",
       "         [2.52879639e+02, 2.38824066e+02, 2.64723148e+01],\n",
       "         [2.53944443e+02, 2.41027802e+02, 3.50000420e+01],\n",
       "         [2.53046295e+02, 2.40324066e+02, 3.48240623e+01]],\n",
       "\n",
       "        [[2.28611115e+02, 2.07222229e+02, 0.00000000e+00],\n",
       "         [2.27083344e+02, 2.04166656e+02, 1.74999988e+00],\n",
       "         [2.28444443e+02, 2.06888885e+02, 2.77776718e-02],\n",
       "         ...,\n",
       "         [2.52000000e+02, 2.37944427e+02, 2.76945038e+01],\n",
       "         [2.53250015e+02, 2.38250015e+02, 3.30833588e+01],\n",
       "         [2.53888885e+02, 2.40000000e+02, 2.85555420e+01]],\n",
       "\n",
       "        [[2.24564804e+02, 2.02666656e+02, 0.00000000e+00],\n",
       "         [2.27750000e+02, 2.05611115e+02, 2.77777731e-01],\n",
       "         [2.28148148e+02, 2.06148148e+02, 4.62961271e-02],\n",
       "         ...,\n",
       "         [2.52833328e+02, 2.37157410e+02, 2.73426456e+01],\n",
       "         [2.52972229e+02, 2.37138885e+02, 2.90833168e+01],\n",
       "         [2.52555557e+02, 2.38333328e+02, 1.87684975e+01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.48166672e+02, 2.25166672e+02, 0.00000000e+00],\n",
       "         [2.46638885e+02, 2.23472214e+02, 0.00000000e+00],\n",
       "         [2.44046295e+02, 2.20046295e+02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [2.42333344e+02, 2.20333344e+02, 0.00000000e+00],\n",
       "         [2.41500000e+02, 2.19500000e+02, 0.00000000e+00],\n",
       "         [2.41064819e+02, 2.18453705e+02, 0.00000000e+00]],\n",
       "\n",
       "        [[2.49000000e+02, 2.25000000e+02, 0.00000000e+00],\n",
       "         [2.46083344e+02, 2.22500000e+02, 0.00000000e+00],\n",
       "         [2.44000000e+02, 2.20000000e+02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [2.44000000e+02, 2.22000000e+02, 0.00000000e+00],\n",
       "         [2.43166656e+02, 2.21166656e+02, 0.00000000e+00],\n",
       "         [2.42194443e+02, 2.19583328e+02, 6.11114502e-01]],\n",
       "\n",
       "        [[2.46499969e+02, 2.21499969e+02, 0.00000000e+00],\n",
       "         [2.44972214e+02, 2.20972214e+02, 0.00000000e+00],\n",
       "         [2.44000000e+02, 2.20000000e+02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [2.43166656e+02, 2.21166656e+02, 0.00000000e+00],\n",
       "         [2.43027771e+02, 2.21027771e+02, 0.00000000e+00],\n",
       "         [2.43509262e+02, 2.21407425e+02, 7.12960720e-01]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b1cd6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 3, 4, 0, 1], dtype=int32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020e0c15",
   "metadata": {},
   "source": [
    "## 2. Wrap the developed DataBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb0e6d",
   "metadata": {},
   "source": [
    "The DataBuilder we developed needs to be distributed to each execution machine for execution, and we need to wrap them in order to serialize.\n",
    "Note: **FLModel requires the incoming DataBuilder return two results (data_set, steps_per_epoch).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d36bee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_builder(\n",
    "    batch_size=5,\n",
    "):\n",
    "    def dataset_builder(folder_path, stage=\"train\"):\n",
    "        import math\n",
    "\n",
    "        import tensorflow as tf\n",
    "\n",
    "        img_height = 180\n",
    "        img_width = 180\n",
    "        data_set = tf.keras.utils.image_dataset_from_directory(\n",
    "            folder_path,\n",
    "            validation_split=0.2,\n",
    "            subset=\"both\",\n",
    "            seed=123,\n",
    "            image_size=(img_height, img_width),\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        if stage == \"train\":\n",
    "            train_dataset = data_set[0]\n",
    "            train_step_per_epoch = math.ceil(len(data_set[0].file_paths) / batch_size)\n",
    "            return train_dataset, train_step_per_epoch\n",
    "        elif stage == \"eval\":\n",
    "            eval_dataset = data_set[1]\n",
    "            eval_step_per_epoch = math.ceil(len(data_set[1].file_paths) / batch_size)\n",
    "            return eval_dataset, eval_step_per_epoch\n",
    "\n",
    "    return dataset_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198128c5",
   "metadata": {},
   "source": [
    "## 3. Build dataset_builder_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a73a04",
   "metadata": {},
   "source": [
    "In the horizontal scenario, the logic for all parties to process data is the same, so we only need a wrapped DataBuilder construction method.\n",
    "Next we build the `dataset_builder_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c051b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_builder_dict = {\n",
    "    alice: create_dataset_builder(\n",
    "        batch_size=5,\n",
    "    ),\n",
    "    bob: create_dataset_builder(\n",
    "        batch_size=5,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e36c7d",
   "metadata": {},
   "source": [
    "## 4. After get dataset_builder_dict, we can pass it into the model for use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602707d",
   "metadata": {},
   "source": [
    "Next we define the model and use the custom data constructed above for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "feea334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_flower_model(input_shape, num_classes, name='model'):\n",
    "    def create_model():\n",
    "        from tensorflow import keras\n",
    "\n",
    "        # Create model\n",
    "\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                tf.keras.layers.Rescaling(1.0 / 255),\n",
    "                tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(),\n",
    "                tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(),\n",
    "                tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(128, activation='relu'),\n",
    "                tf.keras.layers.Dense(num_classes),\n",
    "            ]\n",
    "        )\n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer='adam',\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    return create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60414cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.ml.nn import FLModel\n",
    "from secretflow.security.aggregation import SecureAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f368538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.device.proxy.Actor_Masker'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.device.proxy.Actor_Masker'> with party bob.\n",
      "INFO:root:Create proxy actor <class 'secretflow.device.proxy.ActorPYUFedAvgW'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.device.proxy.ActorPYUFedAvgW'> with party bob.\n"
     ]
    }
   ],
   "source": [
    "device_list = [alice, bob]\n",
    "aggregator = SecureAggregator(alice, [alice, bob])\n",
    "\n",
    "# prepare model\n",
    "num_classes = 5\n",
    "input_shape = (180, 180, 3)\n",
    "\n",
    "# keras model\n",
    "model = create_conv_flower_model(input_shape, num_classes)\n",
    "\n",
    "\n",
    "fed_model = FLModel(\n",
    "    device_list=device_list,\n",
    "    model=model,\n",
    "    aggregator=aggregator,\n",
    "    backend=\"tensorflow\",\n",
    "    strategy=\"fed_avg_w\",\n",
    "    random_seed=1234,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d97af9",
   "metadata": {},
   "source": [
    "The input of our constructed dataset builder is the path of the image dataset, so we need to set the input data as a `Dict` here.\n",
    "```python\n",
    "data = {\n",
    "    alice: folder_path_of_alice,\n",
    "    bob: folder_path_of_bob\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de4b659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:FL Train Params: {'x': {PYURuntime(alice): '/home/beng003/python_project/sf-test/data/datasets/flower_photos', PYURuntime(bob): '/home/beng003/python_project/sf-test/data/datasets/flower_photos'}, 'y': None, 'batch_size': 5, 'batch_sampling_rate': None, 'epochs': 5, 'verbose': 1, 'callbacks': None, 'validation_data': {PYURuntime(alice): '/home/beng003/python_project/sf-test/data/datasets/flower_photos', PYURuntime(bob): '/home/beng003/python_project/sf-test/data/datasets/flower_photos'}, 'shuffle': False, 'class_weight': None, 'sample_weight': None, 'validation_freq': 1, 'aggregate_freq': 2, 'label_decoder': None, 'max_batch_size': 20000, 'prefetch_buffer_size': None, 'sampler_method': 'batch', 'random_seed': 1234, 'dp_spent_step_freq': 1, 'audit_log_dir': None, 'dataset_builder': {PYURuntime(alice): <function create_dataset_builder.<locals>.dataset_builder at 0x7ff26270bd90>, PYURuntime(bob): <function create_dataset_builder.<locals>.dataset_builder at 0x7ff26270be20>}, 'wait_steps': 100, 'self': <secretflow.ml.nn.fl.fl_model.FLModel object at 0x7ff26260f460>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :  50%|█████     | 2/4 [00:01<00:01,  1.37it/s, {'loss': 1.9371605, 'accuracy': 0.15, 'val_loss': 1.5980835, 'val_accuracy': 0.4}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :  50%|█████     | 2/4 [00:01<00:01,  1.94it/s, {'loss': 1.5927668, 'accuracy': 0.28, 'val_loss': 1.5951079, 'val_accuracy': 0.2}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :  50%|█████     | 2/4 [00:00<00:00,  2.02it/s, {'loss': 1.5305115, 'accuracy': 0.4, 'val_loss': 1.5866729, 'val_accuracy': 0.2}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :  50%|█████     | 2/4 [00:00<00:00,  2.02it/s, {'loss': 1.434192, 'accuracy': 0.48, 'val_loss': 1.5454515, 'val_accuracy': 0.2}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :  50%|█████     | 2/4 [00:01<00:01,  1.96it/s, {'loss': 1.2836663, 'accuracy': 0.64, 'val_loss': 1.4539117, 'val_accuracy': 0.2}]\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    alice: path_to_flower_dataset,\n",
    "    bob: path_to_flower_dataset,\n",
    "}\n",
    "history = fed_model.fit(\n",
    "    data,\n",
    "    None,\n",
    "    validation_data=data,\n",
    "    epochs=5,\n",
    "    batch_size=5,\n",
    "    aggregate_freq=2,\n",
    "    sampler_method=\"batch\",\n",
    "    random_seed=1234,\n",
    "    dp_spent_step_freq=1,\n",
    "    dataset_builder=data_builder_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a19de2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54ff96a9",
   "metadata": {},
   "source": [
    "Next, you can use your own dataset to try"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
